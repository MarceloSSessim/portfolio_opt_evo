{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aff924a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile, numpy as np, pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528544a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'weekday'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_20047/1153412201.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# apenas datas >= 1-jan-2018\u001b[39;00m\n\u001b[32m     65\u001b[39m     full_df = full_df[full_df[\u001b[33m\"date\"\u001b[39m] >= start_monday]\n\u001b[32m     66\u001b[39m \n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# segunda de cada semana\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     full_df[\u001b[33m\"week_start\"\u001b[39m] = monday_of(full_df[\u001b[33m\"date\"\u001b[39m])\n\u001b[32m     69\u001b[39m \n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# log-retorno: close de 2ª a 6ª\u001b[39;00m\n\u001b[32m     71\u001b[39m     weekly_ret = (\n",
      "\u001b[32m/tmp/ipykernel_20047/1153412201.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(dt)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m monday_of(dt: pd.Timestamp) -> pd.Timestamp:\n\u001b[32m     18\u001b[39m     \u001b[33m\"\"\"Devolve a segunda-feira da semana de dt.\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dt - pd.Timedelta(days=dt.weekday())\n",
      "\u001b[32m~/portfolio_opt_evo/myenv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6314\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6315\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6316\u001b[39m         ):\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Series' object has no attribute 'weekday'"
     ]
    }
   ],
   "source": [
    "# ============================================================== #\n",
    "# 1) PARÂMETROS\n",
    "# ============================================================== #\n",
    "zip_dir  = Path(\"/mnt/c/Users/msses/Desktop/ETF\")          # onde estão os .zip\n",
    "out_eq_dir = zip_dir / \"weekly_log_returns\"                # saída dos ETFs\n",
    "out_rf_dir = zip_dir / \"DTB1\"                              # mesma pasta do CSV RF\n",
    "rf_csv_path = out_rf_dir / \"DTB4WK.csv\"                    # arquivo já baixado\n",
    "\n",
    "tmp_extract_dir = Path(\"extracted_files\")                  # pasta temporária Linux\n",
    "start_monday = pd.Timestamp(\"2018-01-01\")\n",
    "end_date     = pd.Timestamp(\"2025-03-31\")\n",
    "days_in_year = 252\n",
    "\n",
    "# ============================================================== #\n",
    "# 2) FUNÇÕES AUXILIARES\n",
    "# ============================================================== #\n",
    "def monday_of(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Recebe uma Series de datas e retorna a segunda-feira da semana correspondente.\"\"\"\n",
    "    return series - pd.to_timedelta(series.dt.weekday, unit=\"d\")\n",
    "\n",
    "\n",
    "def split_by_four_weeks(df: pd.DataFrame, date_col: str, out_dir: Path, base_name: str):\n",
    "    \"\"\"\n",
    "    Salva blocos consecutivos de 4 semanas em CSVs.\n",
    "    `base_name` é 'weekly_log_returns' ou 'rf_weekly_log_returns'.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(date_col)\n",
    "    weeks = df[date_col].drop_duplicates().sort_values().to_list()\n",
    "    for i in range(0, len(weeks), 4):\n",
    "        block_weeks = weeks[i : i + 4]\n",
    "        if len(block_weeks) < 4:\n",
    "            break  # ignora bloco incompleto no fim da série\n",
    "        first_monday = block_weeks[0]\n",
    "        first_str = first_monday.strftime(\"%Y_%m_%d\")\n",
    "        filename = f\"{base_name}_{first_str}.csv\"\n",
    "        df_block = df[df[date_col].isin(block_weeks)]\n",
    "        (out_dir / filename).write_text(df_block.to_csv(index=False, float_format=\"%.10f\"))\n",
    "\n",
    "# ============================================================== #\n",
    "# 3) PROCESSAR COTAÇÕES (ZIP → TXT → log_ret)\n",
    "# ============================================================== #\n",
    "out_eq_dir.mkdir(exist_ok=True, parents=True)\n",
    "tmp_extract_dir.mkdir(exist_ok=True, parents=True)\n",
    "df_eq_list = []\n",
    "\n",
    "for file in os.listdir(zip_dir):\n",
    "    if file.lower().endswith(\".zip\"):\n",
    "        with zipfile.ZipFile(zip_dir / file) as z:\n",
    "            z.extractall(tmp_extract_dir)\n",
    "\n",
    "for txt in tmp_extract_dir.glob(\"*.txt\"):\n",
    "    df = pd.read_csv(\n",
    "        txt,\n",
    "        header=None,\n",
    "        names=[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"],\n",
    "        parse_dates=[\"date\"],\n",
    "    )\n",
    "    ticker = txt.stem.split(\"_\")[0]\n",
    "    df[\"ticker\"] = ticker\n",
    "    df_eq_list.append(df)\n",
    "    txt.unlink()  # remove o .txt\n",
    "\n",
    "if df_eq_list:\n",
    "    full_df = pd.concat(df_eq_list, ignore_index=True)\n",
    "    # apenas datas >= 1-jan-2018\n",
    "    full_df = full_df[full_df[\"date\"] >= start_monday]\n",
    "\n",
    "    # segunda de cada semana\n",
    "    full_df[\"week_start\"] = monday_of(full_df[\"date\"])\n",
    "\n",
    "    # log-retorno: close de 2ª a 6ª\n",
    "    weekly_ret = (\n",
    "        full_df.sort_values([\"ticker\", \"date\"])\n",
    "        .groupby([\"ticker\", \"week_start\"])\n",
    "        .agg(first_price=(\"close\", \"first\"), last_price=(\"close\", \"last\"))\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "    )\n",
    "    weekly_ret[\"log_return\"] = np.log(weekly_ret[\"last_price\"] / weekly_ret[\"first_price\"])\n",
    "\n",
    "    # só semanas completas dentro [2018-01-01, 2025-03-28]\n",
    "    weekly_ret = weekly_ret[\n",
    "        (weekly_ret[\"week_start\"] >= start_monday)\n",
    "        & (weekly_ret[\"week_start\"] <= pd.Timestamp(\"2025-03-28\"))\n",
    "    ]\n",
    "\n",
    "    # salvar em blocos de 4 semanas\n",
    "    split_by_four_weeks(\n",
    "        weekly_ret,\n",
    "        \"week_start\",\n",
    "        out_eq_dir,\n",
    "        base_name=\"weekly_log_returns\",\n",
    "    )\n",
    "\n",
    "# ============================================================== #\n",
    "# 4) PROCESSAR RISK-FREE (DTB4WK % a.a. → log_ret semanal)\n",
    "# ============================================================== #\n",
    "out_rf_dir.mkdir(exist_ok=True, parents=True)\n",
    "rf = (\n",
    "    pd.read_csv(rf_csv_path, parse_dates=[\"observation_date\"])\n",
    "    .rename(columns={\"observation_date\": \"date\", \"DTB4WK\": \"annual_rate_pct\"})\n",
    "    .dropna(subset=[\"annual_rate_pct\"])\n",
    ")\n",
    "# diário → log-retorno diário\n",
    "rf[\"rf_log_daily\"] = np.log1p(rf[\"annual_rate_pct\"] / 100) / days_in_year\n",
    "rf = rf[(rf[\"date\"] >= start_monday) & (rf[\"date\"] <= end_date)]\n",
    "\n",
    "# segunda-feira da semana\n",
    "rf[\"week_start\"] = monday_of(rf[\"date\"])\n",
    "\n",
    "# soma dos logs disponíveis na semana\n",
    "rf_weekly = (\n",
    "    rf.groupby(\"week_start\")[\"rf_log_daily\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"rf_log_daily\": \"log_return\"})\n",
    ")\n",
    "\n",
    "# manter apenas semanas que coincidam com as das cotações\n",
    "valid_weeks = weekly_ret[\"week_start\"].unique()\n",
    "rf_weekly = rf_weekly[rf_weekly[\"week_start\"].isin(valid_weeks)]\n",
    "\n",
    "split_by_four_weeks(\n",
    "    rf_weekly,\n",
    "    \"week_start\",\n",
    "    out_rf_dir,\n",
    "    base_name=\"rf_weekly_log_returns\",\n",
    ")\n",
    "\n",
    "print(\"✅ Arquivos semanais gerados em blocos de 4 semanas para cotações e risk-free.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
